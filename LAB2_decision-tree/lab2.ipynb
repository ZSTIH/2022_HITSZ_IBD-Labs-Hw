{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83865623",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import collections\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f152642",
   "metadata": {},
   "source": [
    "## 0、数据处理成csv形式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb38d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['age', 'workclass', 'fnlwgt', 'education', 'educationNum', 'maritalStatus', 'occupation', 'relationship', 'race', 'sex',\n",
    "          'capitalGain', 'capitalLoss', 'hoursPerWeek', 'nativeCountry', 'income']\n",
    "df_train_set = pd.read_csv('./adult.data', names=columns)\n",
    "df_test_set = pd.read_csv('./adult.test', names=columns, skiprows=1) #第一行是非法数据\n",
    "\n",
    "print(df_train_set.head())\n",
    "print(df_test_set.head())\n",
    "df_train_set.to_csv('./train_adult.csv', index=False)\n",
    "df_test_set.to_csv('./test_adult.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff96a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccd1129",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_train_set), len(df_test_set), len(df_test_set.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d8c776",
   "metadata": {},
   "source": [
    "## 1、数据读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f840bf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_set = pd.read_csv('./train_adult.csv')\n",
    "df_train_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b499c4f-bd4f-415d-9311-211091a18f39",
   "metadata": {},
   "source": [
    "## 2、数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a751e794",
   "metadata": {},
   "source": [
    "### 2.1 删除对应属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac775bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_set.drop(['fnlwgt', 'educationNum'], axis=1, inplace=True) # fnlwgt列用处不大，educationNum与education类似\n",
    "df_test_set.drop(['fnlwgt', 'educationNum'], axis=1, inplace=True) # 测试集也去除掉这两列\n",
    "print(df_train_set.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8752b9",
   "metadata": {},
   "source": [
    "### 2.2 重复行记录处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac9368e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_set.drop_duplicates(inplace=True) # 去除重复行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4a6e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc7f88f",
   "metadata": {},
   "source": [
    "### 2.3 缺失值处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d319533f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_set[df_train_set.isna().values == True] # 输出有缺失值的数据行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f703f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_set.dropna(inplace=True) # 去除空行 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac0318d",
   "metadata": {},
   "source": [
    "### 2.4 查看列类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5beb63f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_set.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5845bc34",
   "metadata": {},
   "source": [
    "### 2.5 异常值处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0362dee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_set[df_train_set['workclass'].str.contains(r'\\?', regex=True)] # 查找异常值, 避免与正则表达式的?冲突需要转义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a08cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_set=df_train_set[~df_train_set['workclass'].str.contains(r'\\?', regex=True)]\n",
    "df_train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debec8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#删除有异常值的行\n",
    "new_columns = ['workclass', 'education', 'maritalStatus', 'occupation', 'relationship', 'race', 'sex',\n",
    "               'nativeCountry', 'income']\n",
    "for col in new_columns:\n",
    "        df_train_set = df_train_set[~df_train_set[col].str.contains(r'\\?', regex=True)]\n",
    "df_train_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af9d211",
   "metadata": {},
   "source": [
    "### 2.6 数据可视化，以年龄为例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4bab13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_set['age'].plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03b310e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_set['age'].value_counts().sort_index().plot.line()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c7e31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画出年龄与收入的关系\n",
    "\n",
    "df_train_set = df_train_set.reset_index(drop=True) #重置索引\n",
    "df_train_set['age'].isnull() == True\n",
    "s=df_train_set['age'].value_counts()\n",
    "k=df_train_set['age'][df_train_set['income']==' >50K'].value_counts()\n",
    "sns.set_style(\"whitegrid\")\n",
    "f, ax = plt.subplots(figsize=(18, 9))\n",
    "sns.set_color_codes(\"pastel\")\n",
    "sns.barplot(x=s.index,y=s.values,label='total',color=\"b\")\n",
    "sns.barplot(x=k.index,y=k.values,label='income>50K',color=\"g\")\n",
    "ax.legend(ncol=2, loc=\"upper left\", frameon=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ccedf7",
   "metadata": {},
   "source": [
    "### 2.7 连续型变量处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba523716",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_column = ['age', 'capitalGain', 'capitalLoss', 'hoursPerWeek']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8beefdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_set['age'].max(), df_train_set['age'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc20bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_set['age'].head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e215575c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [0, 25, 50, 75, 100] # 分箱区间左开右闭 (0, 25], (25, 50], ...\n",
    "df_train_set['age'] = pd.cut(df_train_set['age'], bins, labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edf5ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_set['age'].head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2d13f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对测试集数据的年龄属性进行同样处理\n",
    "df_test_set['age'] = pd.cut(df_test_set['age'], bins, labels=False)\n",
    "df_test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922e8efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 探究其它连续属性的取值分布\n",
    "print(\"capitalGain:\")\n",
    "print(df_train_set['capitalGain'].value_counts().sort_index())\n",
    "print(\"max = {}, min = {}\\n\".format(df_train_set['capitalGain'].max(), df_train_set['capitalGain'].min()))\n",
    "\n",
    "print(\"capitalLoss:\")\n",
    "print(df_train_set['capitalLoss'].value_counts().sort_index())\n",
    "print(\"max = {}, min = {}\\n\".format(df_train_set['capitalLoss'].max(), df_train_set['capitalLoss'].min()))\n",
    "\n",
    "print(\"hoursPerWeek:\")\n",
    "print(df_train_set['hoursPerWeek'].value_counts().sort_index())\n",
    "print(\"max = {}, min = {}\\n\".format(df_train_set['hoursPerWeek'].max(), df_train_set['hoursPerWeek'].min()))\n",
    "# 观察知其它连续属性的取值不多，因此不使用分箱法进行处理，而是改为在构建决策树时使用二分法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6e9650",
   "metadata": {},
   "source": [
    "### 2.8 离散型变量处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31eef6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_column = ['workclass', 'education', 'maritalStatus', 'occupation', 'relationship', 'race', 'sex', 'nativeCountry', 'income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51497367",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_set['workclass'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac74e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_set['workclass'].head() #展示前五条"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612dce08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_set['workclass'].value_counts().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9509c2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "workclass_mapping = {' Private': 0, ' Self-emp-not-inc': 1, ' Self-emp-inc': 1, ' Local-gov': 2, \n",
    "                     ' State-gov': 2, ' Federal-gov': 2, ' Without-pay': 3, ' Never-worked': 3}\n",
    "df_train_set['workclass'] = df_train_set['workclass'].map(workclass_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7c3d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_set['workclass'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7e0f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对测试集的workclass属性也进行上述处理\n",
    "df_test_set['workclass'] = df_test_set['workclass'].map(workclass_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b89c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对训练集、测试集同时处理离散型属性education\n",
    "education_mapping = {' Preschool': 0,\n",
    "                     ' 1st-4th': 1,\n",
    "                     ' 5th-6th': 1,\n",
    "                     ' 7th-8th': 2,\n",
    "                     ' 9th': 2,\n",
    "                     ' 10th': 3,\n",
    "                     ' 11th': 3,\n",
    "                     ' 12th': 3,\n",
    "                     ' HS-grad': 3,\n",
    "                     ' Some-college': 4,\n",
    "                     ' Bachelors': 5,\n",
    "                     ' Prof-school': 6,\n",
    "                     ' Assoc-acdm': 7,\n",
    "                     ' Assoc-voc': 8,\n",
    "                     ' Masters': 9,\n",
    "                     ' Doctorate': 10\n",
    "                     }\n",
    "df_train_set['education'] = df_train_set['education'].map(education_mapping)\n",
    "df_test_set['education'] = df_test_set['education'].map(education_mapping)\n",
    "\n",
    "# 对训练集、测试集同时处理离散型属性marital-status\n",
    "marital_status_mapping = {' Married-civ-spouse': 0,\n",
    "                          ' Divorced': 1,\n",
    "                          ' Never-married': 2,\n",
    "                          ' Separated': 3,\n",
    "                          ' Widowed': 4,\n",
    "                          ' Married-spouse-absent': 5,\n",
    "                          ' Married-AF-spouse': 6\n",
    "                          }\n",
    "df_train_set['maritalStatus'] = df_train_set['maritalStatus'].map(marital_status_mapping)\n",
    "df_test_set['maritalStatus'] = df_test_set['maritalStatus'].map(marital_status_mapping)\n",
    "\n",
    "# 对训练集、测试集同时处理离散型属性occupation\n",
    "occupation_mapping = {' Tech-support': 0,\n",
    "                      ' Craft-repair': 1,\n",
    "                      ' Other-service': 2,\n",
    "                      ' Sales': 3,\n",
    "                      ' Exec-managerial': 4,\n",
    "                      ' Prof-specialty': 5,\n",
    "                      ' Handlers-cleaners': 6,\n",
    "                      ' Machine-op-inspct': 7,\n",
    "                      ' Adm-clerical': 8,\n",
    "                      ' Farming-fishing': 9,\n",
    "                      ' Transport-moving': 10,\n",
    "                      ' Priv-house-serv': 11,\n",
    "                      ' Protective-serv': 12,\n",
    "                      ' Armed-Forces': 13\n",
    "                      }\n",
    "df_train_set['occupation'] = df_train_set['occupation'].map(occupation_mapping)\n",
    "df_test_set['occupation'] = df_test_set['occupation'].map(occupation_mapping)\n",
    "\n",
    "# 对训练集、测试集同时处理离散型属性relationship\n",
    "relationship_mapping = {' Wife': 0,\n",
    "                        ' Own-child': 1,\n",
    "                        ' Husband': 2,\n",
    "                        ' Not-in-family': 3,\n",
    "                        ' Other-relative': 4,\n",
    "                        ' Unmarried': 5\n",
    "                        }\n",
    "df_train_set['relationship'] = df_train_set['relationship'].map(relationship_mapping)\n",
    "df_test_set['relationship'] = df_test_set['relationship'].map(relationship_mapping)\n",
    "\n",
    "# 对训练集、测试集同时处理离散型属性race\n",
    "race_mapping = {' White': 0,\n",
    "                ' Asian-Pac-Islander': 1,\n",
    "                ' Amer-Indian-Eskimo': 2,\n",
    "                ' Other': 3,\n",
    "                ' Black': 4\n",
    "                }\n",
    "df_train_set['race'] = df_train_set['race'].map(race_mapping)\n",
    "df_test_set['race'] = df_test_set['race'].map(race_mapping)\n",
    "\n",
    "# 对训练集、测试集同时处理离散型属性sex\n",
    "sex_mapping = {' Female': 0,\n",
    "               ' Male': 1,\n",
    "               }\n",
    "df_train_set['sex'] = df_train_set['sex'].map(sex_mapping)\n",
    "df_test_set['sex'] = df_test_set['sex'].map(sex_mapping)\n",
    "\n",
    "# 对训练集、测试集同时处理离散型属性native-country\n",
    "native_country_mapping = {' United-States': 0,\n",
    "                          ' Cambodia': 1,\n",
    "                          ' England': 2,\n",
    "                          ' Puerto-Rico': 3,\n",
    "                          ' Canada': 4,\n",
    "                          ' Germany': 5,\n",
    "                          ' Outlying-US(Guam-USVI-etc)': 6,\n",
    "                          ' India': 7,\n",
    "                          ' Japan': 8,\n",
    "                          ' Greece': 9,\n",
    "                          ' South': 10,\n",
    "                          ' China': 11,\n",
    "                          ' Cuba': 12,\n",
    "                          ' Iran': 13,\n",
    "                          ' Honduras': 14,\n",
    "                          ' Philippines': 15,\n",
    "                          ' Italy': 16,\n",
    "                          ' Poland': 17,\n",
    "                          ' Jamaica': 18,\n",
    "                          ' Vietnam': 19,\n",
    "                          ' Mexico': 20,\n",
    "                          ' Portugal': 21,\n",
    "                          ' Ireland': 22,\n",
    "                          ' France': 23,\n",
    "                          ' Dominican-Republic': 24,\n",
    "                          ' Laos': 25,\n",
    "                          ' Ecuador': 26,\n",
    "                          ' Taiwan': 27,\n",
    "                          ' Haiti': 28,\n",
    "                          ' Columbia': 29,\n",
    "                          ' Hungary': 30,\n",
    "                          ' Guatemala': 31,\n",
    "                          ' Nicaragua': 32,\n",
    "                          ' Scotland': 33,\n",
    "                          ' Thailand': 34,\n",
    "                          ' Yugoslavia': 35,\n",
    "                          ' El-Salvador': 36,\n",
    "                          ' Trinadad&Tobago': 37,\n",
    "                          ' Peru': 38,\n",
    "                          ' Hong': 39,\n",
    "                          ' Holand-Netherlands': 40\n",
    "                          }\n",
    "df_train_set['nativeCountry'] = df_train_set['nativeCountry'].map(native_country_mapping)\n",
    "df_test_set['nativeCountry'] = df_test_set['nativeCountry'].map(native_country_mapping)\n",
    "\n",
    "# 对训练集、测试集同时处理离散型属性income\n",
    "income_mapping = {' <=50K': 0,\n",
    "                  ' >50K': 1,\n",
    "                  ' <=50K.': 0,\n",
    "                  ' >50K.': 1,\n",
    "                  }\n",
    "df_train_set['income'] = df_train_set['income'].map(income_mapping)\n",
    "df_test_set['income'] = df_test_set['income'].map(income_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa8167f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将预处理后的训练集与测试集数据输出到csv文件\n",
    "df_train_set.to_csv('./train_adult_processed.csv', index=False)\n",
    "df_test_set.to_csv('./test_adult_processed.csv', index=False)\n",
    "\n",
    "columns = list(df_train_set.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d620a6",
   "metadata": {},
   "source": [
    "## 3. 构造决策树，进行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79903ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_gini(df):\n",
    "    \"\"\"\n",
    "    计算数据集的基尼指数\n",
    "    :param df: 数据集\n",
    "    :return: 基尼指数\n",
    "    \"\"\"\n",
    "    p0 = 0\n",
    "    n = 0\n",
    "    for num in df['income']:\n",
    "        if num == 0:\n",
    "            p0 += 1\n",
    "        n += 1\n",
    "    p0 = p0 / n\n",
    "    p1 = 1 - p0\n",
    "    return 1 - p0 * p0 - p1 * p1\n",
    "\n",
    "\n",
    "def split_dataset(df, index, value):\n",
    "    \"\"\"\n",
    "    按照给定的列划分数据集\n",
    "    :param df: 原始数据集\n",
    "    :param index: 指定特征的列索引\n",
    "    :param value: 指定特征的值\n",
    "    :return: 切分后的数据集(left_df, right_df)\n",
    "    \"\"\"\n",
    "    # 将数据集划分为两半，分发给左子树和右子树\n",
    "    # index对应离散型特征时，左子树为符合value的子集，右子树为不符合value的子集\n",
    "    # index对应连续型特征时，左子树为小于等于value的子集，右子树为大于value的子集\n",
    "    feature = columns[index]\n",
    "    if feature in discrete_column:\n",
    "        left_df = df[df[feature] == value]\n",
    "        right_df = df[df[feature] != value]\n",
    "    else:\n",
    "        left_df = df[df[feature] <= value]\n",
    "        right_df = df[df[feature] > value]\n",
    "    return left_df, right_df\n",
    "\n",
    "\n",
    "def choose_best_feature_to_split(df):\n",
    "    \"\"\"\n",
    "    选择最好的特征进行分裂\n",
    "    :param df: 数据集\n",
    "    :return: best_value:(分裂特征的index, 特征的值), best_df:(分裂后的左右子树数据集), min_gini:(选择该属性分裂的最小基尼指数)\n",
    "    \"\"\"\n",
    "    best_value = ()\n",
    "    min_gini = calc_gini(df)\n",
    "    best_df = ()\n",
    "    for index in range(len(columns) - 1): # 最后一列是income，因此要减1\n",
    "        feature = columns[index]\n",
    "        for val in set(df[feature].values):\n",
    "            left_df, right_df = split_dataset(df, index, val)\n",
    "            left_size = len(left_df)\n",
    "            right_size = len(right_df)\n",
    "            if left_size == 0 or right_size == 0:\n",
    "                continue\n",
    "            total_size = left_size + right_size\n",
    "            left_gini = calc_gini(left_df)\n",
    "            right_gini = calc_gini(right_df)\n",
    "            new_gini = left_gini * left_size / total_size + right_gini * right_size / total_size\n",
    "            if new_gini < min_gini:\n",
    "                min_gini = new_gini\n",
    "                best_value = index, val\n",
    "                best_df = left_df, right_df\n",
    "    return best_value, best_df, min_gini\n",
    "\n",
    "\n",
    "def build_decision_tree(df):\n",
    "    \"\"\"\n",
    "    构建CART树\n",
    "    :param df: 数据集\n",
    "    :return: CART树\n",
    "    \"\"\"\n",
    "    best_value, best_df, min_gini = choose_best_feature_to_split(df)\n",
    "    # CART树表示为[leaf_flag, label, left_tree, right_tree, best_value]，其中leaf_flag标记是否为叶子\n",
    "    if len(set(df['income'])) == 1: # 若income的取值只有一种，说明已分“纯”\n",
    "        cart = np.array([1, list(df['income'])[0], None, None, ()], dtype=object)\n",
    "        return cart # 递归结束情况1: 若当前集合的所有样本标签相等,即样本已被分\"纯\",则可以返回该标签值作为一个叶子节点\n",
    "    elif best_value == (): # 若best_value为()，说明已经没有可用的特征\n",
    "        if sum(df['income']) > (len(df['income']) - sum(df['income'])):\n",
    "            label = 1\n",
    "        else:\n",
    "            label = 0\n",
    "        cart = np.array([1, label, None, None, ()], dtype=object)\n",
    "        return cart # 递归结束情况2: 若当前训练集的所有特征都被使用完毕,当前无可用特征但样本仍未分\"纯\"，则返回样本最多的标签作为结果\n",
    "    else:\n",
    "        left_tree = build_decision_tree(best_df[0])\n",
    "        right_tree = build_decision_tree(best_df[1])\n",
    "        cart = np.array([0, -1, left_tree, right_tree, best_value], dtype=object)\n",
    "        return cart\n",
    "\n",
    "\n",
    "def save_decision_tree(cart):\n",
    "    \"\"\"\n",
    "    决策树的存储\n",
    "    :param cart: 训练好的决策树\n",
    "    :return: void\n",
    "    \"\"\"\n",
    "    np.save('cart.npy', cart)\n",
    "    \n",
    "    \n",
    "def load_decision_tree():\n",
    "    \"\"\"\n",
    "    决策树的加载\n",
    "    :return: 保存的决策树\n",
    "    \"\"\"    \n",
    "    \n",
    "    cart = np.load('cart.npy', allow_pickle=True)\n",
    "    return cart\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73fc3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train_set.copy() #防止预处理重新来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b562b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05a0578",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"正在构造决策树，构造所需时间一般在三分钟以内\")\n",
    "cart = build_decision_tree(df_train)\n",
    "save_decision_tree(cart)\n",
    "print(\"决策树构造完毕且已经被存储到文件cart.npy中\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b0db06",
   "metadata": {},
   "source": [
    "## 4. 评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a39e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(cart, df_row):\n",
    "    \"\"\"\n",
    "    用训练好的决策树进行分类\n",
    "    :param cart:决策树模型\n",
    "    :param df_row: 一条测试样本\n",
    "    :return: 预测结果\n",
    "    \"\"\"\n",
    "    while cart[0] != 1:\n",
    "        index, value = cart[4]\n",
    "        feature = columns[index]\n",
    "        if feature in discrete_column:\n",
    "            if df_row[feature] == value:\n",
    "                cart = cart[2]\n",
    "            else:\n",
    "                cart = cart[3]\n",
    "        else:\n",
    "            if df_row[feature] <= value:\n",
    "                cart = cart[2]\n",
    "            else:\n",
    "                cart = cart[3]\n",
    "    return cart[1]\n",
    "\n",
    "\n",
    "def predict(cart, df):\n",
    "    \"\"\"\n",
    "    用训练好的决策树进行分类\n",
    "    :param cart:决策树模型\n",
    "    :param df: 所有测试集\n",
    "    :return: 预测结果\n",
    "    \"\"\"\n",
    "    pred_list = []\n",
    "    for i in range(len(df)):\n",
    "        pred_label = classify(cart, df.iloc[i,:])\n",
    "        if pred_label == -1:\n",
    "            pred_label = random.randint(0, 1) # 防止classify执行到返回-1,但一般不会执行到返回-1\n",
    "        pred_list.append(pred_label)\n",
    "    return pred_list\n",
    "\n",
    "def calc_acc(pred_list, test_list):\n",
    "    \"\"\"\n",
    "    返回预测准确率\n",
    "    :param pred_list: 预测列表\n",
    "    :param test_list: 测试列表\n",
    "    :return: 准确率\n",
    "    \"\"\"\n",
    "    pred = np.array(pred_list)\n",
    "    test = np.array(test_list)\n",
    "    acc = np.sum(pred_list == test_list) / len(test_list)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4022a5b",
   "metadata": {},
   "source": [
    "## 5. 运行模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad375aa3",
   "metadata": {},
   "source": [
    "#### 用测试集评估模型的准确性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7759198",
   "metadata": {},
   "outputs": [],
   "source": [
    "cart = load_decision_tree() # 加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5be5e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = df_test_set['income'].to_numpy()\n",
    "pred_list = predict(cart, df_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f41d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = calc_acc(pred_list, test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee49d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "7600fbc6fd439d66cebe58d8829cae093d4fbb11408f269d0e18344e38b730a5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
